---
phase: 12-fork-system-integration-with-manifests
plan: 02
type: execute
wave: 2
depends_on: ["12-01"]
files_modified:
  - backend/vidpipe/api/routes.py
  - backend/vidpipe/services/manifesting_engine.py
autonomous: true

must_haves:
  truths:
    - "Forked project copies all parent manifest assets with is_inherited=true and shared GCS URLs"
    - "Forked project inherits manifest_id and manifest_version from parent"
    - "Scene manifests are copied for unchanged scenes (index < invalidation boundary)"
    - "Invalidated scenes get no scene manifest (blank for regeneration)"
    - "Modified assets trigger scene invalidation from earliest scene using that asset"
    - "New uploads run through incremental manifesting with face cross-matching against all assets"
    - "Removed assets are excluded from the copy"
    - "Tag collisions avoided: new uploads continue tag numbering from inherited max"
  artifacts:
    - path: "backend/vidpipe/api/routes.py"
      provides: "Extended fork_project with asset copy, scene manifest inheritance, invalidation"
      contains: "_copy_assets_for_fork"
    - path: "backend/vidpipe/services/manifesting_engine.py"
      provides: "process_new_uploads method for incremental manifesting"
      contains: "process_new_uploads"
  key_links:
    - from: "backend/vidpipe/api/routes.py"
      to: "backend/vidpipe/db/models.py"
      via: "Asset rows created with is_inherited=True, inherited_from_asset, inherited_from_project"
      pattern: "is_inherited.*True"
    - from: "backend/vidpipe/api/routes.py"
      to: "backend/vidpipe/db/models.py"
      via: "SceneManifest rows copied for scenes below invalidation boundary"
      pattern: "SceneManifest.*project_id.*new"
    - from: "backend/vidpipe/api/routes.py"
      to: "backend/vidpipe/services/manifesting_engine.py"
      via: "Fork endpoint calls process_new_uploads for new uploads"
      pattern: "process_new_uploads"
    - from: "backend/vidpipe/services/manifesting_engine.py"
      to: "backend/vidpipe/services/face_matching.py"
      via: "Cross-match new face embeddings against inherited embeddings"
      pattern: "cross_match_faces"
---

<objective>
Extend the fork_project endpoint to copy manifest assets with inheritance tracking, inherit scene manifests for unchanged scenes, compute asset-modification invalidation, and run incremental manifesting for new uploads.

Purpose: This is the core backend logic that makes fork-based asset inheritance work. Without this, forked projects lose their entire manifest ecosystem (assets, scene manifests, reference data).
Output: Extended fork endpoint with full asset lifecycle, ManifestingEngine.process_new_uploads method.
</objective>

<execution_context>
@/home/ubuntu/.claude/get-shit-done/workflows/execute-plan.md
@/home/ubuntu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-fork-system-integration-with-manifests/12-RESEARCH.md
@.planning/phases/12-fork-system-integration-with-manifests/12-01-SUMMARY.md

@backend/vidpipe/db/models.py
@backend/vidpipe/api/routes.py
@backend/vidpipe/services/manifesting_engine.py
@backend/vidpipe/services/face_matching.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Asset copy, scene manifest inheritance, and invalidation extension in fork endpoint</name>
  <files>backend/vidpipe/api/routes.py</files>
  <action>
Add two helper functions to `routes.py` BEFORE the `fork_project` endpoint:

**1. `_copy_assets_for_fork` (async function):**
```
async def _copy_assets_for_fork(
    session, source_manifest_id, source_project_id, new_project_id,
    asset_changes  # Optional[AssetChanges]
) -> tuple[list[Asset], list[str]]:
```
- Load all parent assets: `select(Asset).where(Asset.manifest_id == source_manifest_id)`
- Build `removed_set` from `asset_changes.removed_asset_ids` if present
- Build `modified_map` from `asset_changes.modified_assets` if present
- For each parent asset:
  - Skip if `str(asset.id) in removed_set`
  - Create new Asset row with ALL fields copied from parent:
    - `manifest_id=source_manifest_id` (shared manifest)
    - `is_inherited=True`
    - `inherited_from_asset=asset.id`
    - `inherited_from_project=source_project_id`
    - Copy: asset_type, name, manifest_tag, user_tags, reference_image_url, thumbnail_url, description, source, sort_order, reverse_prompt, visual_description, detection_class, detection_confidence, is_face_crop, crop_bbox, face_embedding, clip_embedding, quality_score, source_asset_id
  - If asset.id is in modified_map, apply changes from `modified_map[str(asset.id)].changes`:
    - If "reverse_prompt" in changes: override reverse_prompt
    - If "name" in changes: override name
    - If "visual_description" in changes: override visual_description
    - Set `is_inherited=False` for modified assets (they diverge from parent)
  - `session.add(new_asset)`
- Return `(list_of_new_assets, list_of_modified_asset_tags)` — the modified_asset_tags list is needed for invalidation (collect manifest_tag of each modified parent asset)

**2. `_copy_scene_manifests` (async function):**
```
async def _copy_scene_manifests(
    session, source_project_id, new_project_id, scene_boundary, deleted_set
):
```
- Load all source SceneManifest rows: `select(SceneManifestModel).where(SceneManifestModel.project_id == source_project_id)`
- Build `_old_to_new` mapping function (same as existing in `_compute_invalidation` — map original indices to post-deletion indices, skipping deleted scenes)
- For each source scene manifest:
  - Skip if `sm.scene_index in deleted_set`
  - Compute `new_idx = _old_to_new(sm.scene_index)`
  - Only copy if `new_idx < scene_boundary` (unchanged scenes)
  - Create new SceneManifest with `project_id=new_project_id, scene_index=new_idx` and all other fields copied: manifest_json, composition_shot_type, composition_camera_movement, asset_tags, new_asset_count, selected_reference_tags, cv_analysis_json, continuity_score, rewritten_keyframe_prompt, rewritten_video_prompt
  - `session.add(new_sm)`

**3. Extend `_compute_invalidation`:**
Add a new optional parameter: `modified_asset_tags: Optional[list[str]] = None`

BEFORE the final "No invalidation" return at the end of `_compute_invalidation`, add a new block:
```python
# Asset modification invalidation (Phase 12)
if modified_asset_tags:
    # Need scene manifests to determine which scenes use modified assets
    # Caller must pass scene_manifests for this path
    # Fall back to invalidating from scene 0 if asset_tags not available
    min_keyframe_boundary = 0  # Safe fallback: re-keyframe everything
```

Actually, the asset invalidation path requires scene manifests which `_compute_invalidation` doesn't currently have access to. The cleaner approach:

Add a SEPARATE function `_compute_asset_invalidation_point`:
```python
def _compute_asset_invalidation_point(
    scene_manifests: list,  # SceneManifest rows
    modified_asset_tags: set[str],
    deleted_set: set[int],
) -> int:
    """Find earliest scene using any modified asset (returns scene index, or large number if none)."""
    earliest = float("inf")
    for sm in scene_manifests:
        if sm.scene_index in deleted_set:
            continue
        if sm.asset_tags:
            for tag in sm.asset_tags:
                if tag in modified_asset_tags:
                    earliest = min(earliest, sm.scene_index)
                    break
    return int(earliest) if earliest != float("inf") else -1  # -1 means no match
```

**4. Integrate into `fork_project` endpoint:**

After the existing `_compute_invalidation` call and BEFORE the "Create new project" block:

a) If `request.asset_changes` is not None:
   - Load source scene manifests for asset invalidation check
   - If modified_assets is non-empty, compute `modified_asset_tags` (load parent assets, map id->tag)
   - Call `_compute_asset_invalidation_point` to get the earliest scene affected
   - If it returns a valid index, potentially tighten the invalidation:
     - If the asset invalidation point is EARLIER than current scene_boundary, update scene_boundary and potentially resume_from to "keyframing" (asset changes affect keyframe prompts via rewriter)

b) After `new_project` creation (after `session.add(new_project)` and before commit):
   - Inherit `manifest_id` and `manifest_version`: set `new_project.manifest_id = source.manifest_id`, `new_project.manifest_version = source.manifest_version`
   - Call `_copy_assets_for_fork(session, source.manifest_id, source.id, new_project.id, request.asset_changes)`
   - After scene copying loop completes, call `_copy_scene_manifests(session, source.id, new_project.id, scene_boundary, deleted_set)`

c) If `request.asset_changes` has `new_uploads` (non-empty list):
   - After asset copy but BEFORE commit: import and call `ManifestingEngine.process_new_uploads()` with new_uploads and inherited assets for face cross-matching
   - This runs synchronously during fork creation (small number of images)

Import `SceneManifestModel` is already imported as `SceneManifestModel` at the top of routes.py. Also import `ManifestingEngine` from `vidpipe.services.manifesting_engine`.

IMPORTANT anti-patterns to avoid:
- Do NOT duplicate GCS files — shared `reference_image_url` values
- Do NOT run full manifesting on inherited assets
- Do NOT invalidate all scenes when only adding new uploads (new uploads expand the asset pool, only modifications/removals trigger invalidation)
- Do NOT mutate parent manifest's assets
  </action>
  <verify>
Run `python -c "from vidpipe.api.routes import fork_project, _copy_assets_for_fork, _copy_scene_manifests, _compute_asset_invalidation_point; print('OK')"` from `backend/` directory.
Verify function signatures with: `python -c "import inspect; from vidpipe.api.routes import _copy_assets_for_fork; print(inspect.signature(_copy_assets_for_fork))"`
  </verify>
  <done>Fork endpoint copies assets with is_inherited=True, inherits manifest_id, copies scene manifests for unchanged scenes, computes asset-modification invalidation, and handles removed/modified assets.</done>
</task>

<task type="auto">
  <name>Task 2: ManifestingEngine.process_new_uploads for incremental manifesting</name>
  <files>backend/vidpipe/services/manifesting_engine.py</files>
  <action>
Add a new method `process_new_uploads` to the `ManifestingEngine` class. This method processes ONLY new reference uploads added during a fork, using the existing pipeline stages but scoped to new images only.

```python
async def process_new_uploads(
    self,
    manifest_id: uuid.UUID,
    new_uploads: list,  # list of NewUpload Pydantic models (image_data, name, asset_type, description, tags)
    existing_face_embeddings: list[tuple],  # [(asset_id, embedding_bytes), ...] from inherited assets
) -> list[Asset]:
```

Implementation steps:

1. **Save uploaded images to disk:**
   - For each upload in new_uploads:
     - Decode base64 `image_data`
     - Save to `tmp/manifests/{manifest_id}/uploads/{asset_id}_{name}.{ext}` (same pattern as existing upload path)
     - Create Asset row with: manifest_id, asset_type from upload, name from upload, source="uploaded", description from upload
     - Auto-generate manifest_tag by querying existing assets for this manifest to find max tag number per type (e.g., if CHAR_01 through CHAR_04 exist, next character gets CHAR_05). Use the existing tag pattern: query `select(Asset).where(Asset.manifest_id == manifest_id)`, count by asset_type prefix, increment. This avoids the tag collision pitfall from research.
     - `session.add(new_asset)` and `session.flush()` to get ID

2. **Run YOLO detection on new uploads** (reuse existing Step 2 pattern from `process_manifest`):
   - For each new uploaded asset, run `self.cv_detector.detect_objects_and_faces(img_path)`
   - Create extracted crop assets with proper tag numbering (continuing from existing max)

3. **Generate face embeddings for new face crops** (reuse existing Step 3 pattern):
   - For each new face crop, call `self.face_matcher.generate_embedding(crop_path)`
   - Store as `face_embedding = embedding.tobytes()`

4. **Cross-match faces against ALL embeddings (inherited + new):**
   - Build combined embeddings list: `existing_face_embeddings` (passed in) + new face crop embeddings
   - Call `self.face_matcher.cross_match_faces(combined_embeddings)`
   - Mark duplicates (same pattern as existing Step 3)

5. **Run reverse-prompting on new assets only** (reuse existing Step 4 pattern):
   - Use semaphore rate limiting (5 concurrent)
   - Call `self.reverse_prompter.reverse_prompt_asset(img_path, asset_type, name)` for each new asset

6. **Return the list of newly created Asset objects** (caller needs them for potential tag validation)

Do NOT reassemble contact sheet or change manifest status — the manifest is already READY from the parent. The fork inherits the manifest as-is; new uploads just expand the asset pool.

Do NOT use `self.progress` tracking for this method — it runs synchronously in the fork endpoint, not as a background task.

Key import: `import base64` at the top of the file if not already there.
  </action>
  <verify>
Run `python -c "from vidpipe.services.manifesting_engine import ManifestingEngine; import inspect; sig = inspect.signature(ManifestingEngine.process_new_uploads); print(sig)"` from `backend/` directory — must show `(self, manifest_id, new_uploads, existing_face_embeddings)` parameters.
  </verify>
  <done>ManifestingEngine has process_new_uploads method that processes only new reference images through YOLO, face matching (cross-matched against inherited embeddings), and reverse-prompting, with correct tag numbering to avoid collisions.</done>
</task>

</tasks>

<verification>
1. Import check: `python -c "from vidpipe.api.routes import _copy_assets_for_fork, _copy_scene_manifests, _compute_asset_invalidation_point; print('All functions importable')"` — succeeds
2. Import check: `python -c "from vidpipe.services.manifesting_engine import ManifestingEngine; print(hasattr(ManifestingEngine, 'process_new_uploads'))"` — prints True
3. `grep -n "is_inherited.*True" backend/vidpipe/api/routes.py` — shows Asset creation with inheritance flag
4. `grep -n "SceneManifest.*project_id.*new" backend/vidpipe/api/routes.py` — shows scene manifest copying
5. `grep -n "manifest_id.*source.manifest_id" backend/vidpipe/api/routes.py` — shows manifest_id inheritance
</verification>

<success_criteria>
- Fork endpoint copies all non-removed parent assets with is_inherited=True and shared GCS URLs
- Fork inherits manifest_id and manifest_version from parent
- Scene manifests copied for scenes below invalidation boundary
- Modified assets trigger earlier invalidation via _compute_asset_invalidation_point
- New uploads processed through YOLO + face matching + reverse-prompting
- Face cross-matching includes both inherited and new embeddings
- Tag numbering continues from inherited max (no collisions)
- No GCS file duplication for inherited assets
</success_criteria>

<output>
After completion, create `.planning/phases/12-fork-system-integration-with-manifests/12-02-SUMMARY.md`
</output>
