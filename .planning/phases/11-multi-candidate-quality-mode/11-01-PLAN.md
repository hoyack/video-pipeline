---
phase: 11-multi-candidate-quality-mode
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/vidpipe/db/models.py
  - backend/vidpipe/services/candidate_scoring.py
  - backend/vidpipe/api/routes.py
autonomous: true

must_haves:
  truths:
    - "GenerationCandidate model can store per-candidate video paths, individual scores, composite score, and selection state"
    - "Project model has quality_mode and candidate_count columns with safe defaults for existing projects"
    - "CandidateScoringService computes weighted composite score from manifest adherence (0.35), visual quality (0.25), continuity (0.25), prompt adherence (0.15)"
    - "Scoring uses existing CVAnalysisService for manifest adherence, CLIPEmbeddingService for continuity, and Gemini Flash for visual quality + prompt adherence (batched single call)"
  artifacts:
    - path: "backend/vidpipe/db/models.py"
      provides: "GenerationCandidate ORM model and Project quality_mode/candidate_count columns"
      contains: "class GenerationCandidate"
    - path: "backend/vidpipe/services/candidate_scoring.py"
      provides: "CandidateScoringService with score_candidate and score_all_candidates methods"
      exports: ["CandidateScoringService", "SCORE_WEIGHTS"]
  key_links:
    - from: "backend/vidpipe/services/candidate_scoring.py"
      to: "backend/vidpipe/services/cv_analysis_service.py"
      via: "CVAnalysisService for face matching (manifest adherence)"
      pattern: "CVAnalysisService|analyze_generated_content"
    - from: "backend/vidpipe/services/candidate_scoring.py"
      to: "backend/vidpipe/services/clip_embedding_service.py"
      via: "CLIPEmbeddingService for continuity scoring"
      pattern: "CLIPEmbeddingService|compute_similarity"
---

<objective>
Create the GenerationCandidate database model, extend Project with quality_mode/candidate_count columns, and build the CandidateScoringService that evaluates candidates across four weighted dimensions.

Purpose: Establish the data layer and scoring engine that the pipeline (Plan 02) and API/UI (Plan 03) will use.
Output: GenerationCandidate model in models.py, CandidateScoringService in candidate_scoring.py, Project model extended with quality columns.
</objective>

<execution_context>
@/home/ubuntu/.claude/get-shit-done/workflows/execute-plan.md
@/home/ubuntu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-multi-candidate-quality-mode/11-RESEARCH.md
@backend/vidpipe/db/models.py
@backend/vidpipe/services/cv_analysis_service.py
@backend/vidpipe/services/clip_embedding_service.py
@backend/vidpipe/services/frame_sampler.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: GenerationCandidate model and Project quality columns</name>
  <files>backend/vidpipe/db/models.py</files>
  <action>
Add GenerationCandidate model to models.py following the existing SQLAlchemy 2.0 Mapped[Type] pattern. Place it after the existing VideoClip class (logically related).

```python
class GenerationCandidate(Base):
    """Stores per-candidate video clips with individual and composite quality scores.

    Spec reference: Phase 11 - Multi-Candidate Quality Mode
    """
    __tablename__ = "generation_candidates"

    id: Mapped[uuid.UUID] = mapped_column(primary_key=True, default=uuid.uuid4)
    project_id: Mapped[uuid.UUID] = mapped_column(ForeignKey("projects.id"), index=True)
    scene_index: Mapped[int] = mapped_column(Integer)
    candidate_number: Mapped[int] = mapped_column(Integer)  # 0-based index within batch
    local_path: Mapped[Optional[str]] = mapped_column(String(255), nullable=True)
    thumbnail_path: Mapped[Optional[str]] = mapped_column(String(255), nullable=True)  # First frame JPEG

    # Individual dimension scores (0-10)
    manifest_adherence_score: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
    visual_quality_score: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
    continuity_score: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
    prompt_adherence_score: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
    composite_score: Mapped[Optional[float]] = mapped_column(Float, nullable=True)

    # Scoring details JSON blob for debugging and UI display
    scoring_details: Mapped[Optional[dict]] = mapped_column(JSON, nullable=True)

    # Selection state
    is_selected: Mapped[bool] = mapped_column(Boolean, default=False)
    selected_by: Mapped[str] = mapped_column(String(20), default="auto")  # 'auto' or 'user'

    # Cost tracking
    generation_cost: Mapped[float] = mapped_column(Float, default=0.0)
    scoring_cost: Mapped[float] = mapped_column(Float, default=0.0)

    created_at: Mapped[datetime] = mapped_column(server_default=func.now())
```

Add two columns to the existing Project class (after the existing `manifest_version` column, before `status`):

```python
    # Phase 11: Multi-Candidate Quality Mode
    quality_mode: Mapped[bool] = mapped_column(Boolean, default=False)
    candidate_count: Mapped[int] = mapped_column(Integer, default=1)
```

CRITICAL: Both columns MUST have default values so existing projects (created before Phase 11) load correctly. `quality_mode` defaults to False, `candidate_count` defaults to 1.

Also add the import of GenerationCandidate to any `__init__` if the models file re-exports. Ensure `Index('idx_candidates_project_scene', 'project_id', 'scene_index')` is set via `__table_args__` on GenerationCandidate for efficient per-scene queries:

```python
    __table_args__ = (
        Index("idx_candidates_project_scene", "project_id", "scene_index"),
    )
```

Add the `Index` import at the top of models.py alongside existing sqlalchemy imports.

Extend the `GenerateRequest` pydantic model in routes.py to accept the new fields:

```python
    quality_mode: bool = False
    candidate_count: int = 1
```

Also extend the `ProjectDetail` pydantic response model to include:

```python
    quality_mode: bool = False
    candidate_count: int = 1
```

And the `ProjectListItem`:
```python
    quality_mode: bool = False
    candidate_count: int = 1
```

In the `generate_video()` endpoint in routes.py, pass the new fields when creating the Project:

```python
    quality_mode=request.quality_mode,
    candidate_count=request.candidate_count if request.quality_mode else 1,
```

Add validation in the generate endpoint: `if request.candidate_count < 1 or request.candidate_count > 4: raise HTTPException(422, "candidate_count must be 1-4")`. Also validate `if request.quality_mode and request.candidate_count < 2: raise HTTPException(422, "Quality Mode requires candidate_count >= 2")`.

In the `get_project_detail()` endpoint, include `quality_mode` and `candidate_count` in the response.
  </action>
  <verify>
Run `python -c "from vidpipe.db.models import GenerationCandidate, Project; print('OK')"` from the backend directory. Verify GenerationCandidate has the expected columns by inspecting `GenerationCandidate.__table__.columns.keys()`. Verify Project has `quality_mode` and `candidate_count` attributes.
  </verify>
  <done>
GenerationCandidate model exists with all score columns, selection state, cost tracking, and composite index. Project model has quality_mode (default False) and candidate_count (default 1) columns. GenerateRequest and ProjectDetail schemas include the new fields. Validation rejects invalid candidate_count values.
  </done>
</task>

<task type="auto">
  <name>Task 2: CandidateScoringService with four-dimension composite scoring</name>
  <files>backend/vidpipe/services/candidate_scoring.py</files>
  <action>
Create `backend/vidpipe/services/candidate_scoring.py` implementing the composite scoring pipeline. This is a new file.

The service must:

1. Define score weights as module-level constant:
```python
SCORE_WEIGHTS = {
    "manifest_adherence": 0.35,
    "visual_quality": 0.25,
    "continuity": 0.25,
    "prompt_adherence": 0.15,
}
```

2. Implement `CandidateScoringService` class with lazy-loaded child services (following CVAnalysisService pattern from Phase 9):
   - `_cv_service` -> CVAnalysisService (for manifest adherence via face matching)
   - `_clip_service` -> CLIPEmbeddingService (for continuity scoring)
   - Use lazy getters `_get_cv_service()`, `_get_clip_service()`

3. Implement `async def score_candidate(self, candidate_video_path, scene_index, scene_manifest_json, rewritten_video_prompt, existing_assets, previous_scene_clip_path=None) -> dict`:

   a. **Manifest Adherence (weight 0.35):**
      - Run CVAnalysisService.analyze_generated_content on the candidate clip
      - If semantic_analysis available (it has `manifest_adherence` field): use it directly
      - Else: count face matches vs expected characters from scene_manifest_json asset_tags
      - Score formula: `min(10.0, (matched_faces / max(expected_faces, 1)) * 10)`

   b. **Continuity (weight 0.25):**
      - If scene_index == 0: score = 10.0 (no previous scene)
      - Else: extract first frame from candidate_video_path and last frame from previous_scene_clip_path using cv2 (import inside function per Phase 9 convention)
      - Generate CLIP embeddings for both frames using CLIPEmbeddingService.generate_embedding (run in asyncio.to_thread since CPU-bound)
      - Compute similarity via CLIPEmbeddingService.compute_similarity (static method)
      - Scale cosine similarity [-1,1] to [0,10]: `max(0.0, (similarity + 1.0) / 2.0 * 10.0)`
      - Save extracted frames to tempdir (cleaned up after scoring)

   c. **Visual Quality + Prompt Adherence (weight 0.25 + 0.15) — batched single Gemini call:**
      - Extract first frame of candidate video as JPEG bytes
      - Make ONE Gemini Flash call with the frame image asking for both scores:
        - System prompt: "You are a professional video quality assessor. Analyze this video frame and provide two scores as JSON."
        - User prompt includes: the frame image + the rewritten_video_prompt
        - Request JSON response: `{"visual_quality": N, "prompt_adherence": N}` where N is 0-10
        - visual_quality: rate sharpness, coherence, absence of artifacts, compositional quality
        - prompt_adherence: how well does this frame match the scene description provided
      - Use `google.genai` client (get_vertex_client) with gemini-2.5-flash model
      - Parse JSON response, handle parse failures gracefully (default to 5.0 for both)
      - Track scoring cost estimate: ~$0.01 per candidate for Flash call

   d. **Composite score:** `sum(scores[dim] * weight for dim, weight in SCORE_WEIGHTS.items())`

   e. Return dict with all individual scores + composite + scoring_details dict

4. Implement `async def score_all_candidates(self, candidates_info: list[dict], ...) -> list[dict]`:
   - Score all candidates in parallel using `asyncio.gather()` with `asyncio.Semaphore(3)` to limit concurrent Gemini calls (matching Phase 9 pattern)
   - Return list of score dicts in same order as input

5. Helper functions (module-level, following Phase 10 convention):
   - `def _extract_first_frame(clip_path: str, output_path: str) -> str` — cv2 import inside function
   - `def _extract_last_frame(clip_path: str, output_path: str) -> str` — cv2 import inside function
   - These return the output_path on success

Use `logger = logging.getLogger(__name__)` at module level. Log at INFO for scoring completion, WARNING for Gemini parse failures.

IMPORTANT: Do NOT import cv2 at module level — import inside functions per Phase 9 convention (cv2 imported inside frame_sampler functions to avoid ImportError when opencv not installed).
  </action>
  <verify>
Run `python -c "from vidpipe.services.candidate_scoring import CandidateScoringService, SCORE_WEIGHTS; print(SCORE_WEIGHTS); print('OK')"` from the backend directory. Verify SCORE_WEIGHTS sums to 1.0. Verify CandidateScoringService has score_candidate and score_all_candidates methods.
  </verify>
  <done>
CandidateScoringService exists with four-dimension scoring: manifest adherence (0.35) via CVAnalysisService, continuity (0.25) via CLIP embeddings, visual quality (0.25) + prompt adherence (0.15) via batched Gemini Flash call. Candidates can be scored in parallel with Semaphore(3). Frame extraction helpers use cv2 imported inside functions.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from vidpipe.db.models import GenerationCandidate, Project; assert hasattr(Project, 'quality_mode'); assert hasattr(Project, 'candidate_count'); print('Models OK')"`
2. `python -c "from vidpipe.services.candidate_scoring import CandidateScoringService, SCORE_WEIGHTS; assert abs(sum(SCORE_WEIGHTS.values()) - 1.0) < 0.001; print('Weights OK')"`
3. `python -c "from vidpipe.api.routes import GenerateRequest; r = GenerateRequest(prompt='test'); assert r.quality_mode == False; assert r.candidate_count == 1; print('Schema OK')"`
</verification>

<success_criteria>
- GenerationCandidate model with all score columns, selection state, cost tracking
- Project has quality_mode (bool, default False) and candidate_count (int, default 1)
- GenerateRequest/ProjectDetail schemas include quality mode fields with validation
- CandidateScoringService computes weighted composite from 4 dimensions
- All scoring reuses existing Phase 5/9 services (no new dependencies)
- Gemini visual_quality + prompt_adherence batched into single Flash call
</success_criteria>

<output>
After completion, create `.planning/phases/11-multi-candidate-quality-mode/11-01-SUMMARY.md`
</output>
