---
phase: 09-cv-analysis-pipeline-and-progressive-enrichment
plan: 03
type: execute
wave: 3
depends_on: ["09-02"]
files_modified:
  - backend/vidpipe/pipeline/video_gen.py
  - backend/vidpipe/orchestrator/pipeline.py
autonomous: true

must_haves:
  truths:
    - "CV analysis runs automatically after EACH scene's video generation (not batch at end)"
    - "Assets extracted from scene N are available in the Asset Registry for scene N+1"
    - "SceneManifest.cv_analysis_json is populated with analysis results after each scene"
    - "SceneManifest.continuity_score is set after analysis"
    - "Pipeline continues even if CV analysis fails for a scene (graceful degradation)"
    - "Non-manifest projects skip CV analysis entirely (backward compatible)"
  artifacts:
    - path: "backend/vidpipe/pipeline/video_gen.py"
      provides: "Per-scene CV analysis hook after video clip completion"
      contains: "cv_analysis_service"
    - path: "backend/vidpipe/orchestrator/pipeline.py"
      provides: "Updated pipeline with cv_analysis step logging"
  key_links:
    - from: "backend/vidpipe/pipeline/video_gen.py"
      to: "backend/vidpipe/services/cv_analysis_service.py"
      via: "analyze_generated_content called after each clip completes"
      pattern: "analyze_generated_content"
    - from: "backend/vidpipe/pipeline/video_gen.py"
      to: "backend/vidpipe/services/entity_extraction.py"
      via: "extract_and_register_new_entities called with analysis results"
      pattern: "extract_and_register_new_entities"
    - from: "backend/vidpipe/pipeline/video_gen.py"
      to: "backend/vidpipe/services/cv_analysis_service.py"
      via: "track_appearances persists detection results"
      pattern: "track_appearances"
---

<objective>
Integrate the CV analysis pipeline into the video generation loop so analysis runs after EACH scene completes, enabling progressive enrichment where scene N+1 benefits from assets extracted from scenes 1..N. This is the critical architectural integration that closes the analysis loop.

Purpose: Without this integration, CV analysis exists only as standalone services. This plan wires them into the actual pipeline so that every generated scene is automatically analyzed, new entities are extracted and registered, and the growing Asset Registry progressively improves later scenes' reference selection.

Output: Modified video_gen.py with per-scene analysis hook, updated orchestrator with analysis step tracking.
</objective>

<execution_context>
@/home/ubuntu/.claude/get-shit-done/workflows/execute-plan.md
@/home/ubuntu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/09-cv-analysis-pipeline-and-progressive-enrichment/09-RESEARCH.md
@.planning/phases/09-cv-analysis-pipeline-and-progressive-enrichment/09-01-SUMMARY.md
@.planning/phases/09-cv-analysis-pipeline-and-progressive-enrichment/09-02-SUMMARY.md

@backend/vidpipe/pipeline/video_gen.py
@backend/vidpipe/orchestrator/pipeline.py
@backend/vidpipe/services/cv_analysis_service.py
@backend/vidpipe/services/entity_extraction.py
@backend/vidpipe/db/models.py
@backend/vidpipe/services/reference_selection.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Per-scene CV analysis hook in video generation pipeline</name>
  <files>backend/vidpipe/pipeline/video_gen.py</files>
  <action>
Modify `backend/vidpipe/pipeline/video_gen.py` to add a CV analysis step after each scene's video clip completes successfully.

**Add imports at top of file:**
```python
from vidpipe.services.cv_analysis_service import CVAnalysisService
from vidpipe.services.entity_extraction import identify_new_entities, extract_and_register_new_entities
from vidpipe.db.models import SceneManifest as SceneManifestModel
```
(Note: SceneManifestModel import already exists — keep the existing one, don't duplicate.)

**Create module-level lazy CV analysis service:**
```python
_cv_analysis_service: CVAnalysisService | None = None

def _get_cv_analysis_service() -> CVAnalysisService:
    global _cv_analysis_service
    if _cv_analysis_service is None:
        _cv_analysis_service = CVAnalysisService()
    return _cv_analysis_service
```

**Add new function `_run_post_generation_analysis()`:**

```python
async def _run_post_generation_analysis(
    session: AsyncSession,
    scene: Scene,
    clip: VideoClip,
    project: Project,
    scene_manifest_row: SceneManifestModel | None,
) -> None:
    """Run CV analysis on completed video clip for progressive enrichment.

    This runs AFTER each scene's video clip completes, BEFORE the next scene starts.
    Enables progressive enrichment: assets from scene N feed into scene N+1.

    Gracefully degrades — if analysis fails, logs warning and continues pipeline.
    """
```

Implementation:
1. Guard: `if not project.manifest_id:` return immediately (non-manifest projects skip CV analysis entirely).
2. Guard: `if not clip.local_path:` return (no video to analyze).
3. Load existing assets: `all_assets = await manifest_service.load_manifest_assets(session, project.manifest_id)`.
4. Collect keyframe paths: Query Keyframe records for this scene, collect file_path for start and end keyframes.
5. Call `cv_service.analyze_generated_content(scene_index=scene.scene_index, keyframe_paths=keyframe_paths, clip_path=clip.local_path, scene_manifest_json=scene_manifest_row.manifest_json if scene_manifest_row else None, existing_assets=all_assets)`.
6. **Track appearances**: Call `cv_service.track_appearances(session, project.id, scene.scene_index, analysis_result)`.
7. **Extract new entities**: Call `identify_new_entities(analysis_result, all_assets)` to find unmatched detections. If any found, call `extract_and_register_new_entities(session, project.id, project.manifest_id, scene.scene_index, new_entities, source="CLIP_EXTRACT")`.
8. **Persist analysis to SceneManifest**: If scene_manifest_row exists, set `scene_manifest_row.cv_analysis_json = analysis_result.model_dump(exclude={"clip_embeddings"})` (exclude raw embeddings from JSON — they're large). Set `scene_manifest_row.continuity_score = analysis_result.continuity_score`.
9. Commit session.
10. Log summary: `f"Scene {scene.scene_index}: CV analysis complete — {len(analysis_result.face_matches)} face matches, {analysis_result.new_entity_count} new entities, continuity: {analysis_result.continuity_score:.1f}"`.

**Wrap entire function body in try/except:**
```python
try:
    # ... analysis logic ...
except Exception as e:
    logger.warning(
        f"Scene {scene.scene_index}: CV analysis failed (non-fatal): {e}"
    )
    # Pipeline continues — CV analysis failure is NOT a pipeline failure
```

**Call the hook from `_generate_video_for_scene()`:**

In the existing `_generate_video_for_scene()` function, AFTER the poll_result == "complete" return paths (there are two: one for crash-recovery resume at line ~456 and one in the escalation loop at line ~579), add a call to `_run_post_generation_analysis()` BEFORE the `return` statement.

Specifically:
1. Find the line `if poll_result == "complete":` inside the escalation loop (around line 579). Before `return`, add:
   ```python
   # Phase 9: Post-generation CV analysis for progressive enrichment
   await _run_post_generation_analysis(
       session, scene, clip, project, scene_manifest_row,
   )
   ```
   Note: `scene_manifest_row` is already loaded earlier in the function. If it's not in scope at this point, re-query it or make it available.

2. Similarly for the crash-recovery resume path (around line 456), add the same call after successful poll completion.

**Important considerations:**
- The `scene_manifest_row` variable is already loaded in `_generate_video_for_scene()` around line 425. Move this variable to be set earlier (before the crash-recovery check) so it's available in both code paths, or extract it into a local variable accessible from both paths.
- The analysis call adds ~0.6-1.7 seconds per scene (per research doc timing estimates). This is acceptable overhead vs. 10-60 second video generation.
- Do NOT modify the `generate_videos()` function signature — backward compatible.
  </action>
  <verify>
Run: `cd /home/ubuntu/work/video-pipeline && python -c "from vidpipe.pipeline.video_gen import generate_videos, _run_post_generation_analysis; print('video_gen with CV analysis hook imported OK')"` and verify the function exists: `python -c "import inspect; from vidpipe.pipeline.video_gen import _run_post_generation_analysis; sig = inspect.signature(_run_post_generation_analysis); print('Params:', list(sig.parameters.keys()))"`
  </verify>
  <done>
_run_post_generation_analysis() exists in video_gen.py and is called after each scene's successful video clip generation. It runs CV analysis, tracks appearances, extracts new entities, and persists analysis results to SceneManifest. Wrapped in try/except for graceful degradation. Non-manifest projects skip analysis entirely.
  </done>
</task>

<task type="auto">
  <name>Task 2: Pipeline orchestrator analysis step logging</name>
  <files>backend/vidpipe/orchestrator/pipeline.py</files>
  <action>
Modify `backend/vidpipe/orchestrator/pipeline.py` to add CV analysis awareness to the pipeline orchestrator.

**Changes:**

1. **Add progress callback for CV analysis**: In the video_gen step (Step 3, around line 213), after `progress_callback("Generating video clips...")`, the progress callback now reflects that analysis runs inline with generation. Update the message to:
   ```python
   if progress_callback:
       progress_callback("Generating video clips (with CV analysis)...")
   ```
   This communicates to CLI/API users that video generation now includes per-scene analysis.

2. **Add cv_analysis timing to step_log**: After the video_gen step completes (around line 222), the step_log already tracks "video_gen" timing. Since CV analysis runs inline (inside generate_videos → _generate_video_for_scene → _run_post_generation_analysis), its time is naturally included in the video_gen step duration. Add a comment documenting this:
   ```python
   # Note: video_gen duration includes per-scene CV analysis (Phase 9)
   step_log["video_gen"] = step_duration
   ```

3. **Update _check_completed_steps docstring**: Update the docstring to mention that video clips now include CV analysis results:
   ```python
   """Query database to determine which pipeline steps are complete.

   Note: Video generation (Phase 9+) includes per-scene CV analysis
   for progressive asset enrichment. Analysis results are stored in
   scene_manifests.cv_analysis_json.
   """
   ```

4. **Import AssetAppearance for potential future use**: Add to imports:
   ```python
   from vidpipe.db.models import Project, PipelineRun, Scene, Keyframe, VideoClip, AssetAppearance
   ```
   This makes the model available if we want to add appearance-checking logic to _check_completed_steps later.

This is a minimal change because the heavy lifting happens in video_gen.py's per-scene loop. The orchestrator just needs to be aware that video_gen now includes analysis overhead, and communicate that to the user.
  </action>
  <verify>
Run: `cd /home/ubuntu/work/video-pipeline && python -c "from vidpipe.orchestrator.pipeline import run_pipeline; print('Orchestrator imported OK')"` and verify the import includes AssetAppearance: `python -c "from vidpipe.orchestrator import pipeline; print('AssetAppearance' in dir(pipeline) or 'AssetAppearance' in open('backend/vidpipe/orchestrator/pipeline.py').read())"`
  </verify>
  <done>
Pipeline orchestrator updated with CV analysis awareness. Progress callback message reflects inline analysis. Step log comment documents that video_gen duration includes CV analysis overhead. AssetAppearance imported for future use. No behavioral changes to orchestrator flow — all heavy integration is in video_gen.py.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from vidpipe.pipeline.video_gen import _run_post_generation_analysis"` succeeds
2. `python -c "from vidpipe.orchestrator.pipeline import run_pipeline"` succeeds
3. `grep -c "cv_analysis_service\|_run_post_generation_analysis\|analyze_generated_content" backend/vidpipe/pipeline/video_gen.py` shows >= 3 references
4. `grep "progressive enrichment\|CV analysis" backend/vidpipe/pipeline/video_gen.py` shows integration comments
5. `grep "cv_analysis\|CV analysis" backend/vidpipe/orchestrator/pipeline.py` shows awareness updates
</verification>

<success_criteria>
- CV analysis runs after EACH scene's video clip completes (inline, not batch)
- Progressive enrichment: assets extracted from scene N are in the registry before scene N+1 generates
- SceneManifest.cv_analysis_json populated with analysis results (minus raw embeddings)
- SceneManifest.continuity_score set from analysis
- Non-manifest projects skip CV analysis entirely (backward compatible)
- CV analysis failure does NOT fail the pipeline (graceful degradation with warning log)
- Pipeline orchestrator progress message updated to reflect inline analysis
- No changes to public API signatures (generate_videos, run_pipeline)
</success_criteria>

<output>
After completion, create `.planning/phases/09-cv-analysis-pipeline-and-progressive-enrichment/09-03-SUMMARY.md`
</output>
