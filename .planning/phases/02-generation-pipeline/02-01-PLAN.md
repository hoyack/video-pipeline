---
phase: 02-generation-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - vidpipe/services/vertex_client.py
  - vidpipe/pipeline/storyboard.py
  - vidpipe/schemas/storyboard.py
autonomous: true

must_haves:
  truths:
    - "User submits text prompt and receives structured storyboard with scenes, keyframe prompts, and motion descriptions"
    - "Storyboard includes style guide for cross-scene consistency"
    - "Invalid JSON from LLM is retried with temperature adjustment before failing"
  artifacts:
    - path: "vidpipe/services/vertex_client.py"
      provides: "Google GenAI client wrapper with Vertex AI configuration"
      exports: ["get_vertex_client"]
      min_lines: 30
    - path: "vidpipe/pipeline/storyboard.py"
      provides: "Storyboard generation with Gemini structured output"
      exports: ["generate_storyboard"]
      min_lines: 80
    - path: "vidpipe/schemas/storyboard.py"
      provides: "Pydantic schemas for storyboard structured output"
      exports: ["StoryboardOutput", "SceneSchema", "StyleGuide"]
      min_lines: 40
  key_links:
    - from: "vidpipe/pipeline/storyboard.py"
      to: "vidpipe/services/vertex_client.py"
      via: "get_vertex_client() call"
      pattern: "get_vertex_client\\(\\)"
    - from: "vidpipe/pipeline/storyboard.py"
      to: "vidpipe/schemas/storyboard.py"
      via: "imports StoryboardOutput schema"
      pattern: "from vidpipe\\.schemas\\.storyboard import"
    - from: "vidpipe/pipeline/storyboard.py"
      to: "vidpipe.db.models.Project"
      via: "creates Scene records from storyboard"
      pattern: "Scene\\("
---

<objective>
Implement storyboard generation using Gemini 3 Pro with structured JSON output to transform user text prompts into scene-by-scene breakdowns with keyframe prompts, motion descriptions, and a cross-scene style guide.

Purpose: Establishes the creative blueprint for all downstream generation (keyframes and video), ensuring visual coherence and providing detailed prompts for each scene.

Output: Vertex AI client wrapper, storyboard generator, and Pydantic schemas for structured LLM output.
</objective>

<execution_context>
@/home/ubuntu/.claude/get-shit-done/workflows/execute-plan.md
@/home/ubuntu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/REQUIREMENTS.md
@.planning/phases/02-generation-pipeline/02-RESEARCH.md
@docs/spec.md
@vidpipe/db/models.py
@vidpipe/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Vertex AI client wrapper with google-genai SDK</name>
  <files>vidpipe/services/vertex_client.py</files>
  <action>
Create Vertex AI client wrapper using google-genai SDK v1.0+ in Vertex AI mode.

Implementation:
- Import `from google import genai` and `from google.genai import types`
- Set environment variables: `GOOGLE_GENAI_USE_VERTEXAI='true'`, `GOOGLE_CLOUD_PROJECT` from settings, `GOOGLE_CLOUD_LOCATION` from settings
- Create `get_vertex_client()` function that returns `genai.Client(vertexai=True, project=settings.google_cloud.project_id, location=settings.google_cloud.location)`
- Use singleton pattern: check global variable, create once, return cached instance
- Add module-level docstring explaining Vertex AI mode and ADC authentication
- Import Settings from vidpipe.config

Per research Pattern 1 and Code Example 1: Client uses ADC (Application Default Credentials) automatically in Vertex AI mode. No explicit auth setup needed.

Do NOT use deprecated `google.cloud.aiplatform.vertexai` module — use `google-genai` SDK exclusively.
  </action>
  <verify>
Run: `python -c "from vidpipe.services.vertex_client import get_vertex_client; client = get_vertex_client(); print(type(client))"`

Should output: `<class 'google.genai.client.Client'>` without errors.
  </verify>
  <done>
vidpipe/services/vertex_client.py exists, exports get_vertex_client(), returns google.genai.Client configured for Vertex AI, uses settings from vidpipe.config.
  </done>
</task>

<task type="auto">
  <name>Task 2: Define Pydantic schemas for storyboard structured output</name>
  <files>vidpipe/schemas/storyboard.py</files>
  <action>
Create Pydantic models for Gemini structured output constraint per STOR-02, STOR-03, STOR-04 requirements.

Schemas (matching spec section 5.1):
- `StyleGuide` model with fields: visual_style (str), color_palette (str), camera_style (str)
- `SceneSchema` model with fields: scene_index (int), scene_description (str), start_frame_prompt (str), end_frame_prompt (str), video_motion_prompt (str), transition_notes (str)
- `StoryboardOutput` model with fields: style_guide (StyleGuide), scenes (list[SceneSchema])

Add Field descriptions using Pydantic's Field(description="...") to guide LLM:
- start_frame_prompt: "Detailed image prompt for opening keyframe with composition, lighting, and style details"
- end_frame_prompt: "Detailed image prompt for closing keyframe showing scene progression"
- video_motion_prompt: "Motion/action description for video interpolation between keyframes"
- transition_notes: "How this scene visually connects to the next scene"

Import: `from pydantic import BaseModel, Field`

Per research Pattern 5: These schemas will be passed as `response_schema` to Gemini to constrain JSON output format.
  </action>
  <verify>
Run: `python -c "from vidpipe.schemas.storyboard import StoryboardOutput; import json; print(StoryboardOutput.model_json_schema())"`

Should output valid JSON schema without errors.
  </verify>
  <done>
vidpipe/schemas/storyboard.py exists with StyleGuide, SceneSchema, StoryboardOutput models, all fields have descriptions, schema is importable and generates valid JSON schema.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement storyboard generator with retry logic</name>
  <files>vidpipe/pipeline/storyboard.py</files>
  <action>
Create async storyboard generator function with structured output and retry strategy per STOR-01 through STOR-05 requirements.

Function signature: `async def generate_storyboard(session: AsyncSession, project: Project) -> None`

Implementation flow:
1. Import: get_vertex_client, StoryboardOutput, Scene model, tenacity decorators, config settings
2. Get client via get_vertex_client()
3. Build system prompt instructing Gemini to break script into visual scenes with detailed prompts ensuring continuity
4. Use tenacity @retry decorator with:
   - `stop=stop_after_attempt(3)` per STOR-05
   - `retry=retry_if_exception_type((json.JSONDecodeError, ValidationError))`
   - Reduce temperature by 0.15 on each retry attempt (start at 0.7)
5. Call `await client.aio.models.generate_content()`with:
   - model="gemini-3-pro" (from settings.models.storyboard_llm)
   - contents=[f"{system_prompt}\n\nScript: {project.prompt}"]
   - config=types.GenerateContentConfig(response_mime_type="application/json", response_schema=StoryboardOutput, temperature=0.7)
6. Parse response with `StoryboardOutput.model_validate_json(response.text)`
7. Update Project: project.style_guide = storyboard.style_guide.model_dump(), project.storyboard_raw = storyboard.model_dump()
8. Create Scene records in loop: for scene_data in storyboard.scenes, create Scene(project_id=project.id, scene_index=..., status="pending", ...)
9. Update project.status = "keyframing"
10. Commit session

System prompt example: "You are a cinematic storyboard director. Break the user's script into 3-5 visual scenes optimized for short-form video. For each scene, provide: detailed image prompts for start/end keyframes with composition and lighting details, a motion description for video interpolation, and transition notes for visual continuity. Generate a style guide with visual_style, color_palette, and camera_style to ensure consistency across all scenes."

Per research Pattern 5 (Structured Output) and Pitfall 4 (Invalid JSON retry). Use `client.aio` for async operations.

Do NOT use sync client — only `client.aio.models.generate_content()`.
  </action>
  <verify>
Unit test or manual test:
```python
from vidpipe.pipeline.storyboard import generate_storyboard
from vidpipe.db import async_session, init_database
from vidpipe.db.models import Project
import asyncio

async def test():
    await init_database()
    async with async_session() as session:
        project = Project(prompt="A hero's journey through a mystical forest", style="cinematic", aspect_ratio="16:9", target_clip_duration=4, status="pending")
        session.add(project)
        await session.commit()
        await generate_storyboard(session, project)
        await session.refresh(project)
        print(f"Status: {project.status}, Scenes: {len(project.storyboard_raw['scenes'])}")

asyncio.run(test())
```

Should create Scene records and update project status to "keyframing".
  </verify>
  <done>
vidpipe/pipeline/storyboard.py exists, exports generate_storyboard(), uses Vertex AI client, creates Scene records from structured output, updates project status, handles JSON parse errors with retry.
  </done>
</task>

</tasks>

<verification>
End-to-end test:
1. Create test project with prompt
2. Run generate_storyboard()
3. Verify: Project status = "keyframing", style_guide populated, 3-5 Scene records created with all required fields (start_frame_prompt, end_frame_prompt, video_motion_prompt)
4. Verify: Each scene has unique scene_index, status="pending"
</verification>

<success_criteria>
- [x] Vertex AI client wrapper created using google-genai SDK v1.0+
- [x] Environment variables set for Vertex AI mode
- [x] Pydantic schemas match spec requirements (StyleGuide, SceneSchema, StoryboardOutput)
- [x] Storyboard generator uses structured output with response_schema constraint
- [x] Invalid JSON retried up to 3 times with temperature adjustment (STOR-05)
- [x] Scene records created in database with all prompts populated
- [x] Project status updated to "keyframing" after storyboard generation
- [x] Style guide stored in project.style_guide field
</success_criteria>

<output>
After completion, create `.planning/phases/02-generation-pipeline/02-01-SUMMARY.md`
</output>
